# 22-ç¼“å­˜ä¸æ¶æ„ä¼˜åŒ–

> ä»ç¼“å­˜åˆ°è¯»å†™åˆ†ç¦»ã€åˆ†åº“åˆ†è¡¨ï¼Œæ„å»ºé«˜æ€§èƒ½æ•°æ®åº“æ¶æ„

---

## ğŸ“– æœ¬ç« ç›®æ ‡

- æŒæ¡ç¼“å­˜è®¾è®¡æ¨¡å¼
- è§£å†³ç¼“å­˜å¸¸è§é—®é¢˜
- å®ç°è¯»å†™åˆ†ç¦»
- æŒæ¡åˆ†åº“åˆ†è¡¨ç­–ç•¥
- äº†è§£æ•°æ®åº“ä¸­é—´ä»¶
- è®¾è®¡é«˜å¯ç”¨æ¶æ„

---

## ä¸€ã€ç¼“å­˜è®¾è®¡

### 1.1 ç¼“å­˜æ›´æ–°ç­–ç•¥

```sql
-- ç­–ç•¥1ï¼šCache Asideï¼ˆæ—è·¯ç¼“å­˜ï¼‰
-- æœ€å¸¸ç”¨ï¼Œåº”ç”¨ç¨‹åºç›´æ¥æ“ä½œç¼“å­˜å’Œæ•°æ®åº“

-- è¯»å–æµç¨‹ï¼š
1. å…ˆæŸ¥ç¼“å­˜
2. ç¼“å­˜å‘½ä¸­ â†’ è¿”å›
3. ç¼“å­˜æœªå‘½ä¸­ â†’ æŸ¥æ•°æ®åº“ â†’ å†™å…¥ç¼“å­˜ â†’ è¿”å›

-- æ›´æ–°æµç¨‹ï¼š
1. å…ˆæ›´æ–°æ•°æ®åº“
2. å†åˆ é™¤ç¼“å­˜ï¼ˆä¸æ˜¯æ›´æ–°ç¼“å­˜ï¼ï¼‰

-- Pythonç¤ºä¾‹ï¼š
def get_user(user_id):
    # 1. æŸ¥ç¼“å­˜
    cache_key = f"user:{user_id}"
    user = redis.get(cache_key)
    if user:
        return json.loads(user)

    # 2. æŸ¥æ•°æ®åº“
    sql = "SELECT * FROM users WHERE id = %s"
    user = db.query_one(sql, (user_id,))

    # 3. å†™ç¼“å­˜
    if user:
        redis.setex(cache_key, 3600, json.dumps(user))

    return user

def update_user(user_id, data):
    # 1. æ›´æ–°æ•°æ®åº“
    sql = "UPDATE users SET username = %s WHERE id = %s"
    db.execute(sql, (data['username'], user_id))

    # 2. åˆ é™¤ç¼“å­˜ï¼ˆé‡è¦ï¼ï¼‰
    cache_key = f"user:{user_id}"
    redis.delete(cache_key)
```

```sql
-- ç­–ç•¥2ï¼šRead Through / Write Through
-- ç”±ç¼“å­˜å±‚è‡ªåŠ¨åŒæ­¥æ•°æ®åº“ï¼Œåº”ç”¨ç¨‹åºåªæ“ä½œç¼“å­˜

-- ç­–ç•¥3ï¼šWrite Behindï¼ˆå¼‚æ­¥å†™å…¥ï¼‰
-- å…ˆå†™ç¼“å­˜ï¼Œå¼‚æ­¥æ‰¹é‡å†™æ•°æ®åº“
-- ä¼˜ç‚¹ï¼šæ€§èƒ½é«˜
-- ç¼ºç‚¹ï¼šå¯èƒ½ä¸¢æ•°æ®
```

### 1.2 ç¼“å­˜Keyè®¾è®¡

```python
-- âœ… å¥½çš„Keyè®¾è®¡åŸåˆ™

# 1. ä½¿ç”¨å‘½åç©ºé—´
"user:1"              # ç”¨æˆ·ä¿¡æ¯
"user:1:orders"       # ç”¨æˆ·è®¢å•åˆ—è¡¨
"product:100"         # å•†å“ä¿¡æ¯
"article:50:comments" # æ–‡ç« è¯„è®º

# 2. åŒ…å«ç‰ˆæœ¬å·ï¼ˆæ–¹ä¾¿æ›´æ–°ï¼‰
"user:v1:1"
"product:v2:100"

# 3. ä½¿ç”¨å†’å·åˆ†éš”
"user:1:profile"   # âœ…
"user_1_profile"   # âŒ

# 4. Keyé•¿åº¦é€‚ä¸­ï¼ˆä¸è¦å¤ªé•¿ï¼‰
"u:1"              # âŒ å¤ªçŸ­ï¼Œä¸æ¸…æ™°
"user:id:1:info"   # âœ…
"user:id:1:detailed:information:including:all:fields"  # âŒ å¤ªé•¿

# 5. é¿å…ç‰¹æ®Šå­—ç¬¦
"user:1"           # âœ…
"user 1"           # âŒ ç©ºæ ¼
"user#1"           # âŒ #å·
```

### 1.3 ç¼“å­˜æ•°æ®ç»“æ„é€‰æ‹©

```python
-- Redisæ•°æ®ç»“æ„é€‰æ‹©

# 1. Stringï¼šå•ä¸ªå¯¹è±¡
redis.set("user:1", json.dumps(user_dict))
redis.setex("user:1", 3600, json.dumps(user_dict))  # å¸¦è¿‡æœŸæ—¶é—´

# 2. Hashï¼šå¯¹è±¡å±æ€§
redis.hset("user:1", mapping={
    "id": 1,
    "username": "zhangsan",
    "email": "zhangsan@example.com"
})
redis.hgetall("user:1")

# ä¼˜ç‚¹ï¼šå¯ä»¥å•ç‹¬æ›´æ–°æŸä¸ªå­—æ®µ
redis.hset("user:1", "username", "lisi")

# 3. Listï¼šåˆ—è¡¨æ•°æ®
# æœ€æ–°æ–‡ç« åˆ—è¡¨
redis.lpush("articles:latest", article_id)
redis.ltrim("articles:latest", 0, 99)  # åªä¿ç•™100æ¡
redis.lrange("articles:latest", 0, 19)  # å–å‰20æ¡

# 4. Setï¼šå»é‡é›†åˆ
# ç”¨æˆ·å…³æ³¨åˆ—è¡¨
redis.sadd("user:1:following", 2, 3, 4)
redis.sismember("user:1:following", 2)  # æ˜¯å¦å…³æ³¨

# 5. ZSetï¼šæ’è¡Œæ¦œ
# å•†å“é”€é‡æ’è¡Œ
redis.zadd("products:sales", {
    "product:1": 1000,
    "product:2": 500
})
redis.zrevrange("products:sales", 0, 9)  # Top 10
```

---

## äºŒã€ç¼“å­˜å¸¸è§é—®é¢˜

### 2.1 ç¼“å­˜ç©¿é€

```python
-- é—®é¢˜ï¼šæŸ¥è¯¢ä¸å­˜åœ¨çš„æ•°æ®ï¼Œç¼“å­˜å’Œæ•°æ®åº“éƒ½æ²¡æœ‰

# æ”»å‡»è€…æ•…æ„æŸ¥è¯¢ä¸å­˜åœ¨çš„ID
get_user(999999)  # ä¸åœ¨ç¼“å­˜
# â†’ æŸ¥æ•°æ®åº“ â†’ ä¸å­˜åœ¨
# â†’ ä¸ç¼“å­˜ â†’ ä¸‹æ¬¡è¿˜è¦æŸ¥æ•°æ®åº“

-- âœ… è§£å†³æ–¹æ¡ˆ1ï¼šç¼“å­˜ç©ºå¯¹è±¡
def get_user(user_id):
    cache_key = f"user:{user_id}"
    user = redis.get(cache_key)

    # ç¼“å­˜å‘½ä¸­
    if user is not None:
        if user == "NULL":  # ç©ºå¯¹è±¡
            return None
        return json.loads(user)

    # æŸ¥æ•°æ®åº“
    user = db.query_one("SELECT * FROM users WHERE id = %s", (user_id,))

    # ç¼“å­˜ç»“æœï¼ˆåŒ…æ‹¬ç©ºå¯¹è±¡ï¼‰
    if user:
        redis.setex(cache_key, 3600, json.dumps(user))
    else:
        redis.setex(cache_key, 300, "NULL")  # ç©ºå¯¹è±¡ï¼ŒTTLçŸ­ä¸€äº›

    return user

-- âœ… è§£å†³æ–¹æ¡ˆ2ï¼šå¸ƒéš†è¿‡æ»¤å™¨
from pybloom_live import BloomFilter

# åˆå§‹åŒ–å¸ƒéš†è¿‡æ»¤å™¨
bf = BloomFilter(capacity=1000000, error_rate=0.001)

# å°†æ‰€æœ‰ç”¨æˆ·IDåŠ å…¥å¸ƒéš†è¿‡æ»¤å™¨
user_ids = db.query("SELECT id FROM users")
for user_id in user_ids:
    bf.add(user_id)

def get_user(user_id):
    # å…ˆæ£€æŸ¥å¸ƒéš†è¿‡æ»¤å™¨
    if user_id not in bf:
        return None  # è‚¯å®šä¸å­˜åœ¨ï¼Œç›´æ¥è¿”å›

    # å¯èƒ½å­˜åœ¨ï¼Œç»§ç»­æŸ¥ç¼“å­˜å’Œæ•°æ®åº“
    cache_key = f"user:{user_id}"
    user = redis.get(cache_key)
    if user:
        return json.loads(user)

    user = db.query_one("SELECT * FROM users WHERE id = %s", (user_id,))
    if user:
        redis.setex(cache_key, 3600, json.dumps(user))

    return user
```

### 2.2 ç¼“å­˜å‡»ç©¿

```python
-- é—®é¢˜ï¼šçƒ­ç‚¹æ•°æ®è¿‡æœŸï¼Œç¬é—´å¤§é‡è¯·æ±‚æ‰“åˆ°æ•°æ®åº“

# çƒ­é—¨å•†å“ç¼“å­˜è¿‡æœŸ
get_product(100)  # 1000ä¸ªå¹¶å‘è¯·æ±‚
# â†’ ç¼“å­˜éƒ½miss
# â†’ 1000ä¸ªè¯·æ±‚åŒæ—¶æŸ¥æ•°æ®åº“
# â†’ æ•°æ®åº“å‹åŠ›æš´å¢

-- âœ… è§£å†³æ–¹æ¡ˆ1ï¼šäº’æ–¥é”
import threading

locks = {}

def get_product(product_id):
    cache_key = f"product:{product_id}"
    product = redis.get(cache_key)
    if product:
        return json.loads(product)

    # è·å–é”
    lock_key = f"lock:{cache_key}"
    if product_id not in locks:
        locks[product_id] = threading.Lock()

    with locks[product_id]:
        # åŒé‡æ£€æŸ¥
        product = redis.get(cache_key)
        if product:
            return json.loads(product)

        # æŸ¥æ•°æ®åº“
        product = db.query_one("SELECT * FROM products WHERE id = %s", (product_id,))
        if product:
            redis.setex(cache_key, 3600, json.dumps(product))

    return product

-- âœ… è§£å†³æ–¹æ¡ˆ2ï¼šçƒ­ç‚¹æ•°æ®æ°¸ä¸è¿‡æœŸ
# æ–¹å¼1ï¼šä¸è®¾ç½®TTL
redis.set(cache_key, json.dumps(product))

# æ–¹å¼2ï¼šé€»è¾‘è¿‡æœŸ
product_cache = {
    "data": product,
    "expire_time": time.time() + 3600
}
redis.set(cache_key, json.dumps(product_cache))

# è¯»å–æ—¶æ£€æŸ¥é€»è¾‘è¿‡æœŸ
cache = json.loads(redis.get(cache_key))
if time.time() > cache['expire_time']:
    # å¼‚æ­¥æ›´æ–°ç¼“å­˜
    threading.Thread(target=update_cache, args=(cache_key,)).start()
    # è¿”å›æ—§æ•°æ®
    return cache['data']
```

### 2.3 ç¼“å­˜é›ªå´©

```python
-- é—®é¢˜ï¼šå¤§é‡ç¼“å­˜åŒæ—¶è¿‡æœŸï¼Œæ•°æ®åº“å‹åŠ›æš´å¢

# æ‰€æœ‰å•†å“ç¼“å­˜è®¾ç½®ç›¸åŒTTL
for product in products:
    redis.setex(f"product:{product['id']}", 3600, json.dumps(product))

# 1å°æ—¶åï¼Œæ‰€æœ‰ç¼“å­˜åŒæ—¶è¿‡æœŸ

-- âœ… è§£å†³æ–¹æ¡ˆ1ï¼šè¿‡æœŸæ—¶é—´åŠ éšæœºå€¼
import random

for product in products:
    ttl = 3600 + random.randint(0, 300)  # 3600-3900ç§’
    redis.setex(f"product:{product['id']}", ttl, json.dumps(product))

-- âœ… è§£å†³æ–¹æ¡ˆ2ï¼šRedisé«˜å¯ç”¨
# ä½¿ç”¨Redis Clusteræˆ–å“¨å…µæ¨¡å¼ï¼Œé¿å…RedisæŒ‚æ‰

-- âœ… è§£å†³æ–¹æ¡ˆ3ï¼šé™æµé™çº§
from functools import wraps
import time

def rate_limit(max_calls, time_window):
    calls = []

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            now = time.time()
            # æ¸…ç†è¿‡æœŸè®°å½•
            calls[:] = [c for c in calls if c > now - time_window]

            if len(calls) >= max_calls:
                raise Exception("Rate limit exceeded")

            calls.append(now)
            return func(*args, **kwargs)
        return wrapper
    return decorator

@rate_limit(max_calls=1000, time_window=60)  # æ¯åˆ†é’Ÿæœ€å¤š1000æ¬¡
def query_database():
    return db.query("SELECT ...")
```

---

## ä¸‰ã€è¯»å†™åˆ†ç¦»

### 3.1 è¯»å†™åˆ†ç¦»æ¶æ„

```python
-- æ¶æ„ï¼š
-- 1ä¸»1ä»ï¼šMasterï¼ˆå†™ï¼‰ + Slaveï¼ˆè¯»ï¼‰
-- 1ä¸»å¤šä»ï¼šMasterï¼ˆå†™ï¼‰ + Slave1ï¼ˆè¯»ï¼‰ + Slave2ï¼ˆè¯»ï¼‰

-- MySQLä¸»ä»å¤åˆ¶é…ç½®ï¼ˆç®€åŒ–ï¼‰ï¼š
-- ä¸»åº“(master)é…ç½®ï¼š
-- my.cnf:
-- [mysqld]
-- server-id = 1
-- log-bin = mysql-bin
-- binlog-do-db = your_database

-- ä»åº“(slave)é…ç½®ï¼š
-- my.cnf:
-- [mysqld]
-- server-id = 2
-- relay-log = relay-bin

-- ä»åº“æ‰§è¡Œï¼š
-- CHANGE MASTER TO
--   MASTER_HOST='master_ip',
--   MASTER_USER='repl',
--   MASTER_PASSWORD='password',
--   MASTER_LOG_FILE='mysql-bin.000001',
--   MASTER_LOG_POS=154;
-- START SLAVE;

-- Pythonå®ç°è¯»å†™åˆ†ç¦»ï¼š
import pymysql

class DBRouter:
    def __init__(self):
        # ä¸»åº“è¿æ¥
        self.master = pymysql.connect(
            host='master_ip',
            user='root',
            password='password',
            database='your_database'
        )

        # ä»åº“è¿æ¥
        self.slaves = [
            pymysql.connect(host='slave1_ip', ...),
            pymysql.connect(host='slave2_ip', ...)
        ]
        self.slave_index = 0

    def execute_write(self, sql, params=None):
        """å†™æ“ä½œï¼šä½¿ç”¨ä¸»åº“"""
        cursor = self.master.cursor()
        cursor.execute(sql, params)
        self.master.commit()
        return cursor

    def execute_read(self, sql, params=None):
        """è¯»æ“ä½œï¼šä½¿ç”¨ä»åº“ï¼ˆè½®è¯¢ï¼‰"""
        slave = self.slaves[self.slave_index]
        self.slave_index = (self.slave_index + 1) % len(self.slaves)

        cursor = slave.cursor()
        cursor.execute(sql, params)
        return cursor

# ä½¿ç”¨
db = DBRouter()

# å†™æ“ä½œ
db.execute_write("INSERT INTO users (username) VALUES (%s)", ('zhangsan',))

# è¯»æ“ä½œ
cursor = db.execute_read("SELECT * FROM users WHERE id = %s", (1,))
user = cursor.fetchone()
```

### 3.2 ä¸»ä»å»¶è¿Ÿé—®é¢˜

```python
-- é—®é¢˜ï¼šä¸»ä»å¤åˆ¶æœ‰å»¶è¿Ÿï¼Œå¯èƒ½è¯»ä¸åˆ°åˆšå†™å…¥çš„æ•°æ®

# 1. ç”¨æˆ·æ³¨å†Œ
db.execute_write("INSERT INTO users (username) VALUES ('zhangsan')")  # ä¸»åº“

# 2. ç«‹å³æŸ¥è¯¢
user = db.execute_read("SELECT * FROM users WHERE username = 'zhangsan'")  # ä»åº“
# å¯èƒ½æŸ¥ä¸åˆ°ï¼ï¼ˆä¸»ä»å»¶è¿Ÿï¼‰

-- âœ… è§£å†³æ–¹æ¡ˆ1ï¼šå¼ºåˆ¶è¯»ä¸»åº“
def execute_read(self, sql, params=None, force_master=False):
    if force_master:
        cursor = self.master.cursor()
    else:
        slave = self.slaves[self.slave_index]
        self.slave_index = (self.slave_index + 1) % len(self.slaves)
        cursor = slave.cursor()

    cursor.execute(sql, params)
    return cursor

# æ³¨å†Œåç«‹å³æŸ¥è¯¢ï¼Œå¼ºåˆ¶è¯»ä¸»åº“
user = db.execute_read(
    "SELECT * FROM users WHERE username = 'zhangsan'",
    force_master=True
)

-- âœ… è§£å†³æ–¹æ¡ˆ2ï¼šå†™åè¯»ä¸»åº“ï¼ˆçŸ­æ—¶é—´å†…ï¼‰
import time

class DBRouter:
    def __init__(self):
        self.master = ...
        self.slaves = ...
        self.last_write_time = {}

    def execute_write(self, sql, params=None):
        cursor = self.master.cursor()
        cursor.execute(sql, params)
        self.master.commit()

        # è®°å½•å†™å…¥æ—¶é—´
        import threading
        thread_id = threading.current_thread().ident
        self.last_write_time[thread_id] = time.time()

        return cursor

    def execute_read(self, sql, params=None):
        thread_id = threading.current_thread().ident
        last_write = self.last_write_time.get(thread_id, 0)

        # å†™å1ç§’å†…ï¼Œè¯»ä¸»åº“
        if time.time() - last_write < 1:
            cursor = self.master.cursor()
        else:
            slave = self.slaves[self.slave_index]
            self.slave_index = (self.slave_index + 1) % len(self.slaves)
            cursor = slave.cursor()

        cursor.execute(sql, params)
        return cursor

-- âœ… è§£å†³æ–¹æ¡ˆ3ï¼šä½¿ç”¨ç¼“å­˜
# å†™å…¥æ•°æ®åº“åŒæ—¶å†™å…¥ç¼“å­˜
db.execute_write("INSERT INTO users ...")
redis.setex("user:zhangsan", 60, json.dumps(user))

# è¯»å–æ—¶å…ˆæŸ¥ç¼“å­˜
user = redis.get("user:zhangsan")
if not user:
    user = db.execute_read("SELECT * FROM users WHERE username = 'zhangsan'")
```

---

## å››ã€åˆ†åº“åˆ†è¡¨

### 4.1 ä½•æ—¶åˆ†åº“åˆ†è¡¨

```sql
-- åˆ†åº“åˆ†è¡¨çš„æ—¶æœºï¼š
-- 1. å•è¡¨æ•°æ®é‡ > 500ä¸‡-1000ä¸‡
-- 2. å•è¡¨å¤§å° > 10GB
-- 3. QPS > å•æœºæé™ï¼ˆçº¦5000-10000ï¼‰
-- 4. ç£ç›˜ç©ºé—´ä¸è¶³

-- åˆ†åº“åˆ†è¡¨ç­–ç•¥ï¼š
-- å‚ç›´åˆ†åº“ï¼šæŒ‰ä¸šåŠ¡æ‹†åˆ†ï¼ˆç”¨æˆ·åº“ã€è®¢å•åº“ã€å•†å“åº“ï¼‰
-- å‚ç›´åˆ†è¡¨ï¼šæŒ‰å­—æ®µæ‹†åˆ†ï¼ˆç”¨æˆ·è¡¨ã€ç”¨æˆ·æ‰©å±•è¡¨ï¼‰
-- æ°´å¹³åˆ†åº“ï¼šæŒ‰æ•°æ®æ‹†åˆ†ï¼ˆæŒ‰ç”¨æˆ·IDå“ˆå¸Œï¼‰
-- æ°´å¹³åˆ†è¡¨ï¼šæŒ‰æ•°æ®æ‹†åˆ†ï¼ˆæŒ‰æ—¶é—´ã€æŒ‰IDå–æ¨¡ï¼‰
```

### 4.2 æ°´å¹³åˆ†è¡¨ç­–ç•¥

```python
-- ç­–ç•¥1ï¼šæŒ‰èŒƒå›´åˆ†è¡¨ï¼ˆRangeï¼‰
-- users_0: id 0-1000000
-- users_1: id 1000001-2000000
-- users_2: id 2000001-3000000

def get_table_name(user_id):
    table_index = user_id // 1000000
    return f"users_{table_index}"

# æŸ¥è¯¢
table_name = get_table_name(1500000)  # users_1
sql = f"SELECT * FROM {table_name} WHERE id = %s"

-- ä¼˜ç‚¹ï¼šæ‰©å±•æ–¹ä¾¿
-- ç¼ºç‚¹ï¼šæ•°æ®åˆ†å¸ƒå¯èƒ½ä¸å‡åŒ€

-- ç­–ç•¥2ï¼šæŒ‰å“ˆå¸Œåˆ†è¡¨ï¼ˆHashï¼‰
def get_table_name(user_id):
    table_count = 16  # åˆ†16å¼ è¡¨
    table_index = user_id % table_count
    return f"users_{table_index}"

# æŸ¥è¯¢
table_name = get_table_name(12345)  # users_9
sql = f"SELECT * FROM {table_name} WHERE id = %s"

-- ä¼˜ç‚¹ï¼šæ•°æ®åˆ†å¸ƒå‡åŒ€
-- ç¼ºç‚¹ï¼šæ‰©å®¹å›°éš¾ï¼ˆéœ€è¦æ•°æ®è¿ç§»ï¼‰

-- ç­–ç•¥3ï¼šä¸€è‡´æ€§å“ˆå¸Œ
import hashlib

class ConsistentHash:
    def __init__(self, nodes):
        self.ring = {}
        self.sorted_keys = []

        for node in nodes:
            for i in range(100):  # æ¯ä¸ªèŠ‚ç‚¹100ä¸ªè™šæ‹ŸèŠ‚ç‚¹
                key = self._hash(f"{node}:{i}")
                self.ring[key] = node
                self.sorted_keys.append(key)

        self.sorted_keys.sort()

    def _hash(self, key):
        return int(hashlib.md5(key.encode()).hexdigest(), 16)

    def get_node(self, key):
        if not self.ring:
            return None

        hash_key = self._hash(str(key))

        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå¤§äºç­‰äºhash_keyçš„èŠ‚ç‚¹
        for ring_key in self.sorted_keys:
            if ring_key >= hash_key:
                return self.ring[ring_key]

        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ˆç¯å½¢ï¼‰
        return self.ring[self.sorted_keys[0]]

# ä½¿ç”¨
nodes = ["users_0", "users_1", "users_2", "users_3"]
ch = ConsistentHash(nodes)

table_name = ch.get_node(12345)  # users_2
sql = f"SELECT * FROM {table_name} WHERE id = %s"

-- ç­–ç•¥4ï¼šæŒ‰æ—¶é—´åˆ†è¡¨
-- orders_202401: 2024å¹´1æœˆçš„è®¢å•
-- orders_202402: 2024å¹´2æœˆçš„è®¢å•

def get_table_name(order_date):
    return f"orders_{order_date.strftime('%Y%m')}"

# æŸ¥è¯¢
from datetime import datetime
table_name = get_table_name(datetime(2024, 1, 15))  # orders_202401
sql = f"SELECT * FROM {table_name} WHERE created_at = %s"

-- ä¼˜ç‚¹ï¼šé€‚åˆæ—¥å¿—ã€æµæ°´ç­‰æ—¶é—´åºåˆ—æ•°æ®
-- ç¼ºç‚¹ï¼šå†å²æ•°æ®æŸ¥è¯¢éº»çƒ¦
```

### 4.3 åˆ†åº“åˆ†è¡¨æ³¨æ„äº‹é¡¹

```sql
-- âŒ é—®é¢˜1ï¼šè·¨åº“JOIN
-- ç”¨æˆ·åœ¨users_0ï¼Œè®¢å•åœ¨orders_1
SELECT u.*, o.*
FROM users_0 u
JOIN orders_1 o ON u.id = o.user_id;  -- è·¨åº“ï¼Œæ— æ³•æ‰§è¡Œ

-- âœ… è§£å†³æ–¹æ¡ˆï¼š
-- 1. å†—ä½™å­—æ®µï¼ˆè®¢å•è¡¨å†—ä½™usernameï¼‰
SELECT * FROM orders_1 WHERE user_id = 1;  -- å·²æœ‰username

-- 2. åº”ç”¨å±‚JOIN
users = db.query("SELECT * FROM users_0 WHERE id IN (1,2,3)")
orders = db.query("SELECT * FROM orders_1 WHERE user_id IN (1,2,3)")
# åº”ç”¨å±‚å…³è”

-- 3. å…¨å±€è¡¨ï¼ˆæ•°æ®é‡å°çš„è¡¨æ¯ä¸ªåº“éƒ½æœ‰ä¸€ä»½ï¼‰
-- æ¯ä¸ªåº“éƒ½æœ‰å®Œæ•´çš„categoriesè¡¨

-- âŒ é—®é¢˜2ï¼šåˆ†å¸ƒå¼äº‹åŠ¡
BEGIN;
INSERT INTO users_0 (username) VALUES ('zhangsan');  -- åº“1
INSERT INTO orders_1 (user_id, amount) VALUES (1, 100);  -- åº“2
COMMIT;  -- æ— æ³•ä¿è¯åŸå­æ€§

-- âœ… è§£å†³æ–¹æ¡ˆï¼š
-- 1. é¿å…è·¨åº“äº‹åŠ¡ï¼ˆé€šè¿‡åˆ†ç‰‡é”®è·¯ç”±åˆ°åŒä¸€åº“ï¼‰
-- 2. ä½¿ç”¨åˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆXAã€2PCã€3PCï¼‰
-- 3. ä½¿ç”¨æœ€ç»ˆä¸€è‡´æ€§ï¼ˆæ¶ˆæ¯é˜Ÿåˆ—ã€äº‹ä»¶é©±åŠ¨ï¼‰

-- âŒ é—®é¢˜3ï¼šå…¨å±€å”¯ä¸€ID
-- è‡ªå¢IDåœ¨åˆ†è¡¨åä¼šé‡å¤
INSERT INTO users_0 (id, username) VALUES (1, 'user1');  -- id=1
INSERT INTO users_1 (id, username) VALUES (1, 'user2');  -- id=1é‡å¤ï¼

-- âœ… è§£å†³æ–¹æ¡ˆï¼š
-- 1. é›ªèŠ±ç®—æ³•ï¼ˆSnowflakeï¼‰
-- 2. UUID
-- 3. æ•°æ®åº“åºåˆ—è¡¨
-- 4. Redis INCR

-- âŒ é—®é¢˜4ï¼šæ’åºå’Œåˆ†é¡µ
-- è·¨åˆ†ç‰‡æ’åº
SELECT * FROM users ORDER BY created_at LIMIT 10;
-- éœ€è¦æŸ¥æ‰€æœ‰åˆ†ç‰‡ï¼Œåº”ç”¨å±‚å½’å¹¶æ’åº

-- âœ… è§£å†³æ–¹æ¡ˆï¼š
-- 1. åªåœ¨å•åˆ†ç‰‡å†…æ’åº
SELECT * FROM users_0 ORDER BY created_at LIMIT 10;

-- 2. åº”ç”¨å±‚å½’å¹¶
results = []
for table in ["users_0", "users_1", "users_2"]:
    result = db.query(f"SELECT * FROM {table} ORDER BY created_at LIMIT 10")
    results.extend(result)

# å½’å¹¶æ’åº
results.sort(key=lambda x: x['created_at'])
return results[:10]
```

---

## äº”ã€æ•°æ®åº“ä¸­é—´ä»¶

### 5.1 å¸¸ç”¨ä¸­é—´ä»¶

```python
-- 1. ShardingSphereï¼ˆåŸSharding-JDBCï¼‰
-- åŠŸèƒ½ï¼šåˆ†åº“åˆ†è¡¨ã€è¯»å†™åˆ†ç¦»ã€åˆ†å¸ƒå¼äº‹åŠ¡
-- ç±»å‹ï¼šå®¢æˆ·ç«¯ä»£ç†ï¼ˆJDBCé©±åŠ¨ï¼‰

-- é…ç½®ç¤ºä¾‹ï¼ˆYAMLï¼‰ï¼š
spring:
  shardingsphere:
    datasource:
      names: master,slave0,slave1
      master:
        type: com.zaxxer.hikari.HikariDataSource
        driver-class-name: com.mysql.jdbc.Driver
        jdbc-url: jdbc:mysql://master:3306/db
      slave0:
        jdbc-url: jdbc:mysql://slave0:3306/db
      slave1:
        jdbc-url: jdbc:mysql://slave1:3306/db

    rules:
      sharding:
        tables:
          users:
            actual-data-nodes: ds_$->{0..1}.users_$->{0..15}
            table-strategy:
              standard:
                sharding-column: id
                sharding-algorithm-name: user_inline
        sharding-algorithms:
          user_inline:
            type: INLINE
            props:
              algorithm-expression: users_$->{id % 16}

-- 2. MyCat
-- åŠŸèƒ½ï¼šåˆ†åº“åˆ†è¡¨ã€è¯»å†™åˆ†ç¦»
-- ç±»å‹ï¼šä»£ç†å±‚ä¸­é—´ä»¶ï¼ˆç‹¬ç«‹æœåŠ¡ï¼‰

-- 3. ProxySQL
-- åŠŸèƒ½ï¼šè¯»å†™åˆ†ç¦»ã€æŸ¥è¯¢ç¼“å­˜ã€è´Ÿè½½å‡è¡¡
-- ç±»å‹ï¼šä»£ç†å±‚ä¸­é—´ä»¶

-- 4. MySQL Router
-- åŠŸèƒ½ï¼šè¯»å†™åˆ†ç¦»ã€è´Ÿè½½å‡è¡¡
-- ç±»å‹ï¼šå®˜æ–¹ä¸­é—´ä»¶
```

### 5.2 åˆ†åº“åˆ†è¡¨ä¸­é—´ä»¶é€‰å‹

```sql
-- ShardingSphere vs MyCat

-- ShardingSphereï¼ˆæ¨èï¼‰ï¼š
-- âœ… è½»é‡çº§ï¼ŒJDBCé©±åŠ¨æ–¹å¼
-- âœ… æ€§èƒ½æŸè€—å°
-- âœ… æ”¯æŒSpringBoot
-- âœ… ç¤¾åŒºæ´»è·ƒ
-- âŒ éœ€è¦åµŒå…¥åº”ç”¨

-- MyCatï¼š
-- âœ… ç‹¬ç«‹éƒ¨ç½²ï¼Œåº”ç”¨æ— ä¾µå…¥
-- âœ… æ”¯æŒå¤šç§æ•°æ®åº“
-- âŒ æ€§èƒ½æŸè€—å¤§ï¼ˆç½‘ç»œå¼€é”€ï¼‰
-- âŒ éœ€è¦é¢å¤–è¿ç»´

-- é€‰å‹å»ºè®®ï¼š
-- 1. æ–°é¡¹ç›® â†’ ShardingSphere
-- 2. è€é¡¹ç›®æ”¹é€  â†’ MyCat
-- 3. æ€§èƒ½è¦æ±‚é«˜ â†’ ShardingSphere
```

---

## å…­ã€é«˜å¯ç”¨æ¶æ„

### 6.1 MySQLé«˜å¯ç”¨æ–¹æ¡ˆ

```sql
-- æ–¹æ¡ˆ1ï¼šä¸»ä»å¤åˆ¶ + æ‰‹åŠ¨åˆ‡æ¢
-- Masterï¼ˆå†™ï¼‰ â†’ Slaveï¼ˆè¯»ï¼‰
-- ç¼ºç‚¹ï¼šMasteræŒ‚äº†éœ€è¦æ‰‹åŠ¨æå‡Slave

-- æ–¹æ¡ˆ2ï¼šMHAï¼ˆMaster High Availabilityï¼‰
-- è‡ªåŠ¨æ•…éšœè½¬ç§»
-- MasteræŒ‚äº†è‡ªåŠ¨æå‡Slave

-- æ–¹æ¡ˆ3ï¼šMySQL Group Replication
-- å¤šä¸»å¤åˆ¶ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»
-- MySQL 5.7+

-- æ–¹æ¡ˆ4ï¼šMySQL InnoDB Cluster
-- = MySQL Shell + MySQL Router + MySQL Group Replication
-- MySQL 8.0+ï¼Œå®˜æ–¹æ¨è

-- æ–¹æ¡ˆ5ï¼šäº‘æ•°æ®åº“RDS
-- é˜¿é‡Œäº‘RDSã€è…¾è®¯äº‘CDB
-- è‡ªåŠ¨å¤‡ä»½ã€è‡ªåŠ¨æ•…éšœè½¬ç§»
```

### 6.2 å®¹ç¾æ–¹æ¡ˆ

```sql
-- 1. å¤‡ä»½ç­–ç•¥
-- å…¨é‡å¤‡ä»½ï¼šæ¯å¤©1æ¬¡
-- å¢é‡å¤‡ä»½ï¼šæ¯å°æ—¶1æ¬¡
-- binlogå¤‡ä»½ï¼šå®æ—¶

-- å¤‡ä»½è„šæœ¬ï¼š
#!/bin/bash
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR=/backup/mysql

# å…¨é‡å¤‡ä»½
mysqldump -uroot -p \
  --all-databases \
  --single-transaction \
  --master-data=2 \
  > $BACKUP_DIR/full_$DATE.sql

# å‹ç¼©
gzip $BACKUP_DIR/full_$DATE.sql

-- 2. å¼‚åœ°å®¹ç¾
-- ä¸»æœºæˆ¿ â†’ å¤‡æœºæˆ¿ï¼ˆå¼‚æ­¥å¤åˆ¶ï¼‰
-- Master â†’ Slaveï¼ˆåŒæœºæˆ¿ï¼‰ â†’ Slaveï¼ˆå¼‚åœ°ï¼‰

-- 3. å®šæœŸæ¼”ç»ƒ
-- æ¯å­£åº¦ä¸€æ¬¡æ•…éšœæ¼”ç»ƒ
-- éªŒè¯å¤‡ä»½å¯ç”¨æ€§
-- éªŒè¯åˆ‡æ¢æµç¨‹
```

---

## ä¸ƒã€æ¶æ„ä¼˜åŒ–å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šç”µå•†è®¢å•ç³»ç»Ÿä¼˜åŒ–

```python
-- åœºæ™¯ï¼š
-- ç”¨æˆ·é‡ï¼š1000ä¸‡
-- è®¢å•é‡ï¼š1äº¿+
-- QPSå³°å€¼ï¼š10ä¸‡

-- ä¼˜åŒ–æ–¹æ¡ˆï¼š

# 1. ç¼“å­˜çƒ­ç‚¹æ•°æ®
# ç”¨æˆ·ä¿¡æ¯ï¼ˆè¯»å¤šå†™å°‘ï¼‰
redis.setex(f"user:{user_id}", 3600, json.dumps(user))

# å•†å“ä¿¡æ¯ï¼ˆè¯»å¤šå†™å°‘ï¼‰
redis.setex(f"product:{product_id}", 3600, json.dumps(product))

# 2. è¯»å†™åˆ†ç¦»
db_router.execute_write("INSERT INTO orders ...")  # ä¸»åº“
db_router.execute_read("SELECT * FROM orders ...")  # ä»åº“

# 3. åˆ†åº“åˆ†è¡¨
# è®¢å•è¡¨æŒ‰user_idå“ˆå¸Œåˆ†16å¼ è¡¨
def get_order_table(user_id):
    return f"orders_{user_id % 16}"

# 4. å¼‚æ­¥å¤„ç†
# è®¢å•åˆ›å»ºåï¼Œå¼‚æ­¥å‘é€æ¶ˆæ¯
order = create_order()
mq.send("order_created", order)

# 5. é™æµé™çº§
from ratelimit import limits, sleep_and_retry

@sleep_and_retry
@limits(calls=1000, period=1)  # æ¯ç§’1000æ¬¡
def create_order():
    ...
```

### æ¡ˆä¾‹2ï¼šç¤¾äº¤feedæµä¼˜åŒ–

```python
-- åœºæ™¯ï¼š
-- ç”¨æˆ·é‡ï¼š5000ä¸‡
-- å…³æ³¨å…³ç³»ï¼šå¹³å‡200äºº
-- å‘å¸–QPSï¼š5000

-- ä¼˜åŒ–æ–¹æ¡ˆï¼š

# 1. æ¨æ‹‰ç»“åˆï¼ˆPush + Pullï¼‰
# æ¨æ¨¡å¼ï¼šç²‰ä¸å°‘çš„ç”¨æˆ·ï¼ˆ<1000ï¼‰
def publish_post(user_id, post):
    # æŸ¥è¯¢ç²‰ä¸åˆ—è¡¨
    fans = db.query("SELECT follower_id FROM follows WHERE user_id = %s", (user_id,))

    # æ¨é€åˆ°ç²‰ä¸çš„feedæµ
    for fan in fans:
        redis.zadd(f"feed:{fan['follower_id']}", {post['id']: post['created_at']})

# æ‹‰æ¨¡å¼ï¼šç²‰ä¸å¤šçš„ç”¨æˆ·ï¼ˆ>=1000ï¼‰
def publish_post(user_id, post):
    # åªå­˜å‚¨è‡ªå·±çš„å¸–å­åˆ—è¡¨
    redis.zadd(f"posts:{user_id}", {post['id']: post['created_at']})

# è¯»å–feedæµ
def get_feed(user_id):
    # 1. ä»ç¼“å­˜è¯»å–æ¨é€çš„å¸–å­
    feed = redis.zrevrange(f"feed:{user_id}", 0, 19)

    # 2. æ‹‰å–å…³æ³¨çš„å¤§Vçš„å¸–å­
    big_vs = redis.smembers(f"user:{user_id}:big_v_following")
    for big_v in big_vs:
        posts = redis.zrevrange(f"posts:{big_v}", 0, 9)
        feed.extend(posts)

    # 3. å½’å¹¶æ’åº
    feed.sort(key=lambda x: x['created_at'], reverse=True)
    return feed[:20]

# 2. çƒ­ç‚¹æ•°æ®é¢„åŠ è½½
# çƒ­é—¨å¸–å­é¢„åŠ è½½åˆ°CDN
cdn.upload(post['image_url'])

# 3. åˆ†çº§å­˜å‚¨
# æœ€è¿‘1å¤©ï¼šMySQL + Redis
# 1-30å¤©ï¼šMySQL
# 30å¤©ä»¥ä¸Šï¼šå½’æ¡£åˆ°HBase/ES
```

---

## å…«ã€æœ¬ç« æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹

1. **ç¼“å­˜è®¾è®¡**ï¼š
   - Cache Asideæ¨¡å¼
   - åˆç†çš„Keyè®¾è®¡
   - é€‰æ‹©åˆé€‚çš„æ•°æ®ç»“æ„

2. **ç¼“å­˜é—®é¢˜**ï¼š
   - ç©¿é€ï¼šå¸ƒéš†è¿‡æ»¤å™¨ã€ç¼“å­˜ç©ºå¯¹è±¡
   - å‡»ç©¿ï¼šäº’æ–¥é”ã€çƒ­ç‚¹æ•°æ®ä¸è¿‡æœŸ
   - é›ªå´©ï¼šè¿‡æœŸæ—¶é—´åŠ éšæœºå€¼ã€é«˜å¯ç”¨

3. **è¯»å†™åˆ†ç¦»**ï¼š
   - ä¸»ä»å¤åˆ¶æ¶æ„
   - å¤„ç†ä¸»ä»å»¶è¿Ÿ
   - è´Ÿè½½å‡è¡¡

4. **åˆ†åº“åˆ†è¡¨**ï¼š
   - æŒ‰èŒƒå›´ã€æŒ‰å“ˆå¸Œã€æŒ‰æ—¶é—´
   - å…¨å±€å”¯ä¸€ID
   - è·¨åº“JOINã€åˆ†å¸ƒå¼äº‹åŠ¡

5. **ä¸­é—´ä»¶**ï¼š
   - ShardingSphere
   - MyCat
   - ProxySQL

6. **é«˜å¯ç”¨**ï¼š
   - MHAã€Group Replication
   - å¤‡ä»½ç­–ç•¥
   - å®¹ç¾æ–¹æ¡ˆ

### ä¸‹ä¸€æ­¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ åº”è¯¥èƒ½å¤Ÿï¼š
- âœ… è®¾è®¡åˆç†çš„ç¼“å­˜æ–¹æ¡ˆ
- âœ… è§£å†³ç¼“å­˜å¸¸è§é—®é¢˜
- âœ… å®ç°è¯»å†™åˆ†ç¦»
- âœ… è¿›è¡Œåˆ†åº“åˆ†è¡¨è®¾è®¡
- âœ… æ„å»ºé«˜å¯ç”¨æ¶æ„

**ğŸ‰ æ­å–œå®Œæˆç¬¬äº”ç« ï¼**

ä¸‹ä¸€ç« ï¼š[ç¬¬å…­ç«  - æœ€ä½³å®è·µ](./23-SQLç¼–å†™è§„èŒƒ.md)
