# 06-查询优化

> 对应课程：第16-22讲（ORDER BY、随机查询、慢查询、幻读、性能优化）
> 学习时间：3-4小时
> 前置要求：已完成05-索引与性能优化学习

---

## 核心知识点概览

### 本章内容

- **第16讲**：ORDER BY工作原理
- **第17讲**：如何随机选择数据
- **第18讲**：SQL语句性能差异
- **第19讲**：为什么查询很慢
- **第20讲**：幻读问题
- **第21讲**：为什么锁这么多
- **第22讲**：提高性能的"饮鸩止渴"方法

---

## 第16讲：ORDER BY工作原理

### 核心知识点

**排序算法**：
1. **全字段排序**：sort_buffer放所有字段
2. **rowid排序**：sort_buffer只放排序字段+主键，再回表

**选择依据**：
- `max_length_for_sort_data`参数
- 单行长度 < max_length_for_sort_data：全字段排序
- 单行长度 > max_length_for_sort_data：rowid排序

**优化方向**：
1. 使用索引避免排序
2. 增大sort_buffer_size
3. 只返回需要的字段

### 实操练习

```sql
USE mysql_study;

-- 创建测试表
CREATE TABLE order_test (
    id INT PRIMARY KEY AUTO_INCREMENT,
    city VARCHAR(16),
    name VARCHAR(16),
    age INT,
    score INT,
    KEY idx_city (city)
) ENGINE=InnoDB;

-- 插入测试数据
INSERT INTO order_test (city, name, age, score)
SELECT
    ELT(FLOOR(1 + RAND() * 5), '北京', '上海', '广州', '深圳', '杭州'),
    CONCAT('user', n),
    20 + FLOOR(RAND() * 30),
    60 + FLOOR(RAND() * 40)
FROM
    (SELECT @n := @n + 1 AS n FROM
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t1,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t2,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t3,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t4,
        (SELECT @n := 0) init
    ) nums
LIMIT 10000;

-- 查看排序相关参数
SHOW VARIABLES LIKE 'sort_buffer_size';
SHOW VARIABLES LIKE 'max_length_for_sort_data';

-- 场景1：使用filesort（需要排序）
EXPLAIN SELECT city, name, age FROM order_test
WHERE city = '北京'
ORDER BY name;
-- Extra: Using filesort

-- 场景2：使用索引避免排序
CREATE INDEX idx_city_name ON order_test(city, name);

EXPLAIN SELECT city, name, age FROM order_test
WHERE city = '北京'
ORDER BY name;
-- Extra: Using index condition（无filesort）

-- 场景3：全字段排序 vs rowid排序
-- 临时修改参数观察差异
SET SESSION max_length_for_sort_data = 16;

EXPLAIN SELECT city, name, age, score FROM order_test
WHERE city = '北京'
ORDER BY name;
-- 单行长度超过16，使用rowid排序

SET SESSION max_length_for_sort_data = 1024;

EXPLAIN SELECT city, name, age, score FROM order_test
WHERE city = '北京'
ORDER BY name;
-- 单行长度小于1024，使用全字段排序

-- 场景4：无法使用索引的排序
EXPLAIN SELECT * FROM order_test
WHERE city = '北京'
ORDER BY age;
-- Extra: Using filesort（age不在索引中）

-- 优化：创建联合索引
CREATE INDEX idx_city_age ON order_test(city, age);

EXPLAIN SELECT * FROM order_test
WHERE city = '北京'
ORDER BY age;
-- Extra: 无filesort

-- 场景5：ORDER BY多个字段
EXPLAIN SELECT * FROM order_test
WHERE city = '北京'
ORDER BY name, age;
-- 需要索引(city, name, age)

-- 清理索引
DROP INDEX idx_city_name ON order_test;
DROP INDEX idx_city_age ON order_test;
```

---

## 第17讲：随机选择数据

### 核心知识点

**错误方案**：`ORDER BY RAND()`
- 需要全表扫描
- 使用临时表
- 对所有行生成随机数并排序
- 性能极差

**优化方案**：
1. **随机limit方案**：先随机offset，再limit
2. **随机id方案**：生成随机id范围查询
3. **两次查询方案**：先count，再随机offset

### 实操练习

```sql
-- 使用order_test表（10000条数据）

-- 方案1：ORDER BY RAND()（不推荐）
EXPLAIN SELECT * FROM order_test ORDER BY RAND() LIMIT 3;
-- Extra: Using temporary; Using filesort
-- 性能很差！

SELECT * FROM order_test ORDER BY RAND() LIMIT 3;

-- 方案2：随机offset（适合总数不大的场景）
-- 先获取总数
SELECT COUNT(*) INTO @total FROM order_test;

-- 生成随机offset
SET @offset = FLOOR(RAND() * (@total - 3));

-- 使用LIMIT offset
SET @sql = CONCAT('SELECT * FROM order_test LIMIT ', @offset, ', 3');
PREPARE stmt FROM @sql;
EXECUTE stmt;
DEALLOCATE PREPARE stmt;

-- 方案3：随机id（适合id连续的场景）
-- 获取id范围
SELECT MIN(id), MAX(id) INTO @min_id, @max_id FROM order_test;

-- 生成随机id
SET @random_id = FLOOR(@min_id + RAND() * (@max_id - @min_id));

-- 查询
SELECT * FROM order_test WHERE id >= @random_id LIMIT 3;

-- 方案4：优化的随机id（处理id不连续）
-- 获取三个随机id
SELECT id INTO @id1 FROM order_test
WHERE id >= FLOOR(@min_id + RAND() * (@max_id - @min_id))
LIMIT 1;

SELECT id INTO @id2 FROM order_test
WHERE id >= FLOOR(@min_id + RAND() * (@max_id - @min_id))
LIMIT 1;

SELECT id INTO @id3 FROM order_test
WHERE id >= FLOOR(@min_id + RAND() * (@max_id - @min_id))
LIMIT 1;

-- 查询这三条记录
SELECT * FROM order_test WHERE id IN (@id1, @id2, @id3);

-- 方案5：应用层随机（推荐）
-- 1. 查询总数
SELECT COUNT(*) FROM order_test;

-- 2. 应用层生成3个随机offset
-- 3. 分别查询
-- SELECT * FROM order_test LIMIT offset1, 1;
-- SELECT * FROM order_test LIMIT offset2, 1;
-- SELECT * FROM order_test LIMIT offset3, 1;
```

---

## 第18讲：SQL性能差异

### 核心知识点

**相同逻辑，性能差异的原因**：
1. 隐式类型转换
2. 隐式字符编码转换
3. 函数操作导致索引失效

### 实操练习

```sql
USE mysql_study;

-- 场景1：隐式类型转换
CREATE TABLE type_test (
    id INT PRIMARY KEY AUTO_INCREMENT,
    phone VARCHAR(11),
    KEY idx_phone (phone)
) ENGINE=InnoDB;

INSERT INTO type_test (phone)
SELECT CONCAT('138', LPAD(n, 8, '0'))
FROM
    (SELECT @n := @n + 1 AS n FROM
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t1,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t2,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t3,
        (SELECT @n := 0) init
    ) nums
LIMIT 1000;

-- 正确：使用字符串
EXPLAIN SELECT * FROM type_test WHERE phone = '13800000001';
-- key: idx_phone

-- 错误：使用数字（隐式转换）
EXPLAIN SELECT * FROM type_test WHERE phone = 13800000001;
-- key: NULL（索引失效！）
-- 原因：WHERE CAST(phone AS UNSIGNED) = 13800000001

-- 场景2：函数导致索引失效
CREATE TABLE func_test (
    id INT PRIMARY KEY AUTO_INCREMENT,
    create_time DATETIME,
    name VARCHAR(50),
    KEY idx_create_time (create_time)
) ENGINE=InnoDB;

INSERT INTO func_test (create_time, name)
SELECT
    DATE_ADD('2024-01-01', INTERVAL FLOOR(RAND() * 365) DAY),
    CONCAT('user', n)
FROM
    (SELECT @n := @n + 1 AS n FROM
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t1,
        (SELECT 1 UNION SELECT 2 UNION SELECT 3 UNION SELECT 4) t2,
        (SELECT @n := 0) init
    ) nums
LIMIT 100;

-- 错误：在索引字段上使用函数
EXPLAIN SELECT * FROM func_test
WHERE YEAR(create_time) = 2024;
-- key: NULL（索引失效）

-- 正确：改写查询条件
EXPLAIN SELECT * FROM func_test
WHERE create_time BETWEEN '2024-01-01' AND '2024-12-31 23:59:59';
-- key: idx_create_time

-- 场景3：字符编码转换
-- 创建不同字符集的表
CREATE TABLE utf8_table (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(50),
    KEY idx_name (name)
) ENGINE=InnoDB CHARSET=utf8;

CREATE TABLE utf8mb4_table (
    id INT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(50),
    KEY idx_name (name)
) ENGINE=InnoDB CHARSET=utf8mb4;

INSERT INTO utf8_table (name) VALUES ('张三'), ('李四');
INSERT INTO utf8mb4_table (name) VALUES ('张三'), ('李四');

-- JOIN时字符集不同
EXPLAIN SELECT * FROM utf8_table t1
JOIN utf8mb4_table t2 ON t1.name = t2.name;
-- 可能导致索引失效（需要字符集转换）

-- 解决：统一字符集
ALTER TABLE utf8_table CONVERT TO CHARACTER SET utf8mb4;
```

---

## 第19讲：查询很慢的原因

### 核心知识点

**偶尔慢的原因**：
1. 在等MDL锁
2. 在等flush（刷脏页）
3. 在等行锁

**一直慢的原因**：
1. 没有索引
2. 字段有函数操作
3. 扫描行数过多

### 实操练习

```sql
-- 场景1：等待MDL锁
-- 参考第06讲MDL锁演示

-- 查看MDL锁等待
SELECT * FROM sys.schema_table_lock_waits;

-- 场景2：等待flush
SHOW ENGINE INNODB STATUS\G
-- 查看LOG部分，看checkpoint age

-- 场景3：等待行锁
-- 查看当前锁等待
SELECT
    r.trx_id waiting_trx_id,
    r.trx_mysql_thread_id waiting_thread,
    r.trx_query waiting_query,
    b.trx_id blocking_trx_id,
    b.trx_mysql_thread_id blocking_thread,
    b.trx_query blocking_query
FROM information_schema.INNODB_LOCK_WAITS w
JOIN information_schema.INNODB_TRX r ON w.requesting_trx_id = r.trx_id
JOIN information_schema.INNODB_TRX b ON w.blocking_trx_id = b.trx_id;

-- 或使用sys库（MySQL 5.7+）
SELECT * FROM sys.innodb_lock_waits;

-- 场景4：长事务导致慢查询
-- 查找长事务（超过60秒）
SELECT
    trx_id,
    trx_started,
    trx_mysql_thread_id,
    trx_query
FROM information_schema.INNODB_TRX
WHERE TIME_TO_SEC(TIMEDIFF(NOW(), trx_started)) > 60;

-- 杀掉长事务
KILL <thread_id>;

-- 场景5：监控慢查询
-- 开启慢查询日志
SHOW VARIABLES LIKE 'slow_query%';
SHOW VARIABLES LIKE 'long_query_time';

SET GLOBAL slow_query_log = 'ON';
SET GLOBAL long_query_time = 2;  -- 2秒

-- 查看慢查询日志文件
SHOW VARIABLES LIKE 'slow_query_log_file';

-- 分析慢查询（使用pt-query-digest工具）
-- pt-query-digest /path/to/slow.log
```

---

## 第20讲：幻读

### 核心知识点

**幻读定义**：同一事务内，两次查询返回的行数不同

**InnoDB解决幻读**：
- 快照读：MVCC
- 当前读：Next-Key Lock（记录锁+间隙锁）

**幻读的影响**：
1. 破坏语义：查询结果不一致
2. 破坏数据一致性
3. 破坏binlog正确性

### 实操练习

```sql
USE mysql_study;

-- 准备数据（使用之前的lock_test表）
DELETE FROM lock_test;
INSERT INTO lock_test VALUES
(1, 'a', 10),
(5, 'b', 20),
(10, 'c', 30);

-- 场景1：快照读避免幻读
-- === 窗口A ===
START TRANSACTION;
SELECT * FROM lock_test WHERE age > 15;
-- 结果：2行（id=5和id=10）

-- 等待窗口B...

-- 再次查询（快照读）
SELECT * FROM lock_test WHERE age > 15;
-- 结果：还是2行（MVCC保证）

COMMIT;
```

```sql
-- === 窗口B ===
INSERT INTO lock_test VALUES (15, 'd', 25);
COMMIT;
```

```sql
-- 场景2：当前读产生幻读？
-- === 窗口A ===
START TRANSACTION;

-- 当前读（加锁）
SELECT * FROM lock_test WHERE age > 15 FOR UPDATE;
-- 加了Next-Key Lock，锁住了间隙

-- 等待窗口B...
```

```sql
-- === 窗口B ===
START TRANSACTION;

-- 尝试插入
INSERT INTO lock_test VALUES (7, 'x', 25);
-- 阻塞！被间隙锁锁住

-- 窗口A commit后才能继续
```

```sql
-- === 窗口A ===
-- 再次查询
SELECT * FROM lock_test WHERE age > 15 FOR UPDATE;
-- 结果一致，无幻读

COMMIT;
```

```sql
-- 场景3：幻读导致的binlog问题
-- 假设没有间隙锁，考虑以下场景：

-- === 窗口A（事务1）===
START TRANSACTION;
UPDATE lock_test SET age = age + 1 WHERE age > 15;
-- 更新2行

-- 等待窗口B...

COMMIT;  -- 假设此时提交
```

```sql
-- === 窗口B（事务2）===
INSERT INTO lock_test VALUES (20, 'y', 25);
COMMIT;  -- 先提交
```

```sql
-- 问题：
-- binlog顺序（STATEMENT格式）：
-- 1. INSERT (事务2)
-- 2. UPDATE (事务1)

-- 从库执行结果：
-- INSERT: id=20, age=25
-- UPDATE: id=20, age=26（被更新了！）

-- 主库实际结果：
-- id=20, age=25（未被更新）

-- 数据不一致！这就是为什么需要间隙锁
```

---

## 第21讲：为什么锁这么多

### 核心知识点

**加锁原则**（REPEATABLE READ）：
1. 加锁基本单位是Next-Key Lock
2. 查找过程中访问到的对象才加锁
3. 唯一索引等值查询，Next-Key Lock退化为Record Lock
4. 索引等值查询最后一个值不满足，Next-Key Lock退化为Gap Lock

### 实操练习

```sql
-- 使用lock_test表
DELETE FROM lock_test;
INSERT INTO lock_test VALUES
(5, 'a', 10),
(10, 'b', 20),
(15, 'c', 30);

-- 案例1：等值查询间隙锁
-- === 窗口A ===
START TRANSACTION;

-- 查询不存在的记录
SELECT * FROM lock_test WHERE id = 7 FOR UPDATE;
-- 加间隙锁：(5, 10)

-- 等待窗口B...
```

```sql
-- === 窗口B ===
-- 插入间隙内
INSERT INTO lock_test VALUES (6, 'x', 15);
-- 阻塞！

-- 插入间隙外
INSERT INTO lock_test VALUES (12, 'y', 25);
-- 成功
```

```sql
-- 案例2：非唯一索引等值查询
CREATE INDEX idx_age ON lock_test(age);

-- === 窗口A ===
START TRANSACTION;

SELECT * FROM lock_test WHERE age = 20 FOR UPDATE;
-- 加锁：
-- 1. idx_age上：(10, 20], (20, 30)（Next-Key Lock + Gap Lock）
-- 2. 主键id=10上：Record Lock

-- 等待窗口B...
```

```sql
-- === 窗口B ===
-- 插入age=15（在间隙内）
INSERT INTO lock_test VALUES (7, 'x', 15);
-- 阻塞！

-- 插入age=25（在间隙内）
INSERT INTO lock_test VALUES (17, 'y', 25);
-- 阻塞！

-- 更新id=10
UPDATE lock_test SET name = 'bbb' WHERE id = 10;
-- 阻塞！
```

```sql
-- 案例3：范围查询
-- === 窗口A ===
START TRANSACTION;

SELECT * FROM lock_test WHERE id >= 10 AND id < 15 FOR UPDATE;
-- 加锁：(5, 10], (10, 15]

-- 等待窗口B...
```

```sql
-- === 窗口B ===
INSERT INTO lock_test VALUES (8, 'x', 15);
-- 阻塞！

INSERT INTO lock_test VALUES (12, 'y', 25);
-- 阻塞！

INSERT INTO lock_test VALUES (17, 'z', 35);
-- 成功
```

---

## 第22讲："饮鸩止渴"的方法

### 核心知识点

**短期救急方案**（有副作用）：

1. **短连接风暴**：使用max_connections
2. **慢查询性能**：查询重写或索引提示
3. **QPS突增**：限流

**不推荐但可救急**：
- 增大max_connections（可能OOM）
- 跳过权限验证：--skip-grant-tables
- kill慢查询

### 实操练习

```sql
-- 方案1：增大连接数（临时方案）
SHOW VARIABLES LIKE 'max_connections';

-- 紧急情况下临时增大
SET GLOBAL max_connections = 2000;

-- 注意：连接数过多可能导致OOM

-- 查看当前连接数
SHOW STATUS LIKE 'Threads_connected';
SHOW STATUS LIKE 'Max_used_connections';

-- 方案2：减少连接时间
-- 查看wait_timeout
SHOW VARIABLES LIKE 'wait_timeout';

-- 减小超时时间（生产环境慎用）
SET GLOBAL wait_timeout = 60;

-- 方案3：杀掉慢查询
-- 查找长时间运行的查询
SELECT
    id,
    user,
    host,
    db,
    command,
    time,
    state,
    info
FROM information_schema.PROCESSLIST
WHERE command != 'Sleep'
  AND time > 10
ORDER BY time DESC;

-- 杀掉查询
KILL QUERY <id>;  -- 只杀查询，不断开连接
KILL <id>;        -- 杀连接

-- 方案4：慢查询重写（query rewrite插件）
-- MySQL 5.7+支持

-- 安装插件
INSTALL PLUGIN REWRITER SONAME 'rewriter.so';

-- 添加重写规则
INSERT INTO query_rewrite.rewrite_rules (pattern, replacement)
VALUES (
    'SELECT * FROM users WHERE name = ?',
    'SELECT * FROM users FORCE INDEX(idx_name) WHERE name = ?'
);

-- 加载规则
CALL query_rewrite.flush_rewrite_rules();

-- 方案5：从库延迟处理
-- 如果主从延迟，可以：
-- 1. 临时关闭从库（防止影响查询）
-- 2. 降低主库写入压力
-- 3. 增加从库资源

STOP SLAVE;
-- 处理完问题后
START SLAVE;
```

---

## 重点总结

### 查询优化

1. **ORDER BY**：
   - 优先使用索引避免排序
   - 了解全字段排序 vs rowid排序

2. **随机查询**：
   - 避免ORDER BY RAND()
   - 使用随机offset或随机id方案

3. **性能差异**：
   - 避免隐式类型转换
   - 避免在索引字段上使用函数
   - 注意字符编码统一

### 锁与事务

4. **幻读**：
   - 快照读：MVCC
   - 当前读：Next-Key Lock
   - 间隙锁防止幻读，保证binlog一致性

5. **加锁规则**：
   - Next-Key Lock为基本单位
   - 理解锁退化条件

### 性能问题排查

6. **查询慢的原因**：
   - 等锁（MDL锁、行锁）
   - 刷脏页
   - 长事务

7. **救急方案**：
   - 增大连接数（临时）
   - 杀慢查询
   - 查询重写

---

## 课后思考

1. 为什么ORDER BY RAND()性能很差？如何优化？
2. 间隙锁的作用是什么？为什么需要间隙锁？
3. 如何判断一个查询是否走了索引？
4. 长事务有哪些危害？如何避免？

---

## 下一步

完成本讲后，继续学习：
- **07-高可用架构.md**：主从复制、读写分离、高可用方案
